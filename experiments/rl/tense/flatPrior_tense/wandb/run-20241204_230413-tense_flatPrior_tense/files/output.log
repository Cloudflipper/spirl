Reading configurations for Franka
[40m[97mInitializing Franka sim[0m
exp_dir:	./experiments
conf_path:	spirl/configs/rl/tense/conf.py
general:
	seed:	0
	agent:	<class 'spirl.rl.agents.prior_sac_agent.ActionPriorSACAgent'>
	environment:	<class 'spirl.rl.envs.kitchen.KitchenEnv'>
	data_dir:	.
	num_epochs:	100
	max_rollout_len:	280
	n_steps_per_epoch:	50000
	n_warmup_steps:	5000.0
agent:
	policy:	<class 'spirl.rl.policies.prior_policies.LearnedPriorAugmentedPIPolicy'>
	policy_params:
		action_dim:	6
		input_dim:	39
		n_layers:	5
		nz_mid:	256
		max_action_range:	1.0
		prior_model:	<class 'spirl.models.bc_mdl.BCMdl'>
		prior_model_params:
			state_dim:	39
			action_dim:	6
		prior_model_checkpoint:	./experiments/skill_prior_learning/tense
	critic:	<class 'spirl.rl.components.critic.MLPCritic'>
	critic_params:
		action_dim:	6
		input_dim:	39
		output_dim:	1
		n_layers:	2
		nz_mid:	256
		action_input:	True
	replay:	<class 'spirl.rl.components.replay_buffer.UniformReplayBuffer'>
	replay_params:
		capacity:	100000.0
		dump_replay:	False
	clip_q_target:	False
	batch_size:	256
	log_video_caption:	True
	td_schedule_params:
		p:	1.0
	device:	cpu
	env_params:
data:
	dataset_spec:
		dataset_class:	<class 'spirl.data.tense.kitchen_data_loader.D4RLSequenceSplitDataset'>
		n_actions:	6
		state_dim:	39
		env_name:	tensegrity_env-v0
		res:	128
		crop_rand_subseq:	True
		max_seq_len:	280
env:
	reward_norm:	1.0
	device:	cpu
	seed:	0
sampler:
ckpt_path:	None
notes:	non-hierarchical RL experiments in tensegrity env
mpi:
	rank:	0
	is_chef:	True
	num_workers:	1
/home/zzz/spirl-master/spirl/modules/layers.py:12: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.
  nn.init.xavier_normal(m.weight.data)
Loading from: ./experiments/skill_prior_learning/tense/weights
=> loading checkpoint './experiments/skill_prior_learning/tense/weights/weights_ep19.pth'
=> loaded checkpoint './experiments/skill_prior_learning/tense/weights/weights_ep19.pth' (epoch 19)
Loading from: ./experiments/skill_prior_learning/tense/weights
=> loading checkpoint './experiments/skill_prior_learning/tense/weights/weights_ep19.pth'
=> loaded checkpoint './experiments/skill_prior_learning/tense/weights/weights_ep19.pth' (epoch 19)
Warmup data collection for 5000.0 steps...
Traceback (most recent call last):
  File "spirl/rl/train.py", line 327, in <module>
    RLTrainer(args=get_args())
  File "spirl/rl/train.py", line 77, in __init__
    self.train(start_epoch)
  File "spirl/rl/train.py", line 105, in train
    self.warmup()
  File "spirl/rl/train.py", line 198, in warmup
    warmup_experience_batch, _ = self.sampler.sample_batch(
  File "/home/zzz/spirl-master/spirl/rl/components/sampler.py", line 44, in sample_batch
    agent_output = self.sample_action(self._obs)
  File "/home/zzz/spirl-master/spirl/rl/components/sampler.py", line 33, in sample_action
    return self._agent.act(obs)
  File "/home/zzz/spirl-master/spirl/rl/components/agent.py", line 52, in act
    return self._act_rand(obs)
  File "/home/zzz/spirl-master/spirl/rl/agents/ac_agent.py", line 39, in _act_rand
    policy_output = self.policy.sample_rand(map2torch(obs, self.policy.device))
  File "/home/zzz/spirl-master/spirl/rl/policies/prior_policies.py", line 54, in sample_rand
    output_dict = self.forward(obs[None])
  File "/home/zzz/spirl-master/spirl/rl/policies/prior_policies.py", line 149, in forward
    return LearnedPriorAugmentedPolicy.forward(self, obs)
  File "/home/zzz/spirl-master/spirl/rl/policies/prior_policies.py", line 75, in forward
    policy_output = super().forward(obs)
  File "/home/zzz/spirl-master/spirl/rl/components/policy.py", line 25, in forward
    output_dist = self._compute_action_dist(obs)
  File "/home/zzz/spirl-master/spirl/rl/policies/prior_policies.py", line 50, in _compute_action_dist
    return self.net.compute_learned_prior(obs, first_only=True)
  File "/home/zzz/spirl-master/spirl/models/bc_mdl.py", line 94, in compute_learned_prior
    return self._compute_output_dist(inputs)
  File "/home/zzz/spirl-master/spirl/models/bc_mdl.py", line 80, in _compute_output_dist
    return MultivariateGaussian(self.net(inputs))
  File "/home/zzz/miniconda3/envs/mujoco/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zzz/spirl-master/spirl/modules/subnetworks.py", line 45, in forward
    out = super().forward(*inp)
  File "/home/zzz/spirl-master/spirl/utils/general_utils.py", line 538, in forward
    return super().forward(inp)
  File "/home/zzz/miniconda3/envs/mujoco/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/zzz/miniconda3/envs/mujoco/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zzz/miniconda3/envs/mujoco/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/zzz/miniconda3/envs/mujoco/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zzz/miniconda3/envs/mujoco/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 96, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/zzz/miniconda3/envs/mujoco/lib/python3.8/site-packages/torch/nn/functional.py", line 1847, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x60 and 39x128)
