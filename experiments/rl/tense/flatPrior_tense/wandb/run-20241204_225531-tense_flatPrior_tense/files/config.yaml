_wandb:
    value:
        cli_version: 0.18.5
        m: []
        python_version: 3.8.20
        t:
            "1":
                - 1
                - 41
                - 55
            "2":
                - 1
                - 41
                - 55
            "3":
                - 16
                - 23
                - 55
            "4": 3.8.20
            "5": 0.18.5
            "8":
                - 5
            "12": 0.18.5
            "13": linux-x86_64
agent_batch_size:
    value: 256
agent_clip_q_target:
    value: false
agent_critic_params_action_dim:
    value: 6
agent_critic_params_action_input:
    value: true
agent_critic_params_input_dim:
    value: 39
agent_critic_params_n_layers:
    value: 2
agent_critic_params_nz_mid:
    value: 256
agent_critic_params_output_dim:
    value: 1
agent_device:
    value: cpu
agent_log_video_caption:
    value: true
agent_policy_params_action_dim:
    value: 6
agent_policy_params_input_dim:
    value: 39
agent_policy_params_max_action_range:
    value: 1
agent_policy_params_n_layers:
    value: 5
agent_policy_params_nz_mid:
    value: 256
agent_policy_params_prior_model_checkpoint:
    value: ./experiments/skill_prior_learning/kitchen/flat
agent_policy_params_prior_model_params_action_dim:
    value: 6
agent_policy_params_prior_model_params_state_dim:
    value: 39
agent_replay_params_capacity:
    value: 100000
agent_replay_params_dump_replay:
    value: false
agent_td_schedule_params_p:
    value: 1
ckpt_path:
    value: null
conf_path:
    value: spirl/configs/rl/tense/conf.py
data_dataset_spec_crop_rand_subseq:
    value: true
data_dataset_spec_env_name:
    value: tensegrity_env-v0
data_dataset_spec_max_seq_len:
    value: 280
data_dataset_spec_n_actions:
    value: 6
data_dataset_spec_res:
    value: 128
data_dataset_spec_state_dim:
    value: 39
env_device:
    value: cpu
env_reward_norm:
    value: 1
exp_dir:
    value: ./experiments
general_data_dir:
    value: .
general_max_rollout_len:
    value: 280
general_n_steps_per_epoch:
    value: 50000
general_n_warmup_steps:
    value: 5000
general_num_epochs:
    value: 100
general_seed:
    value: 42
mpi_is_chef:
    value: true
mpi_num_workers:
    value: 1
mpi_rank:
    value: 0
notes:
    value: non-hierarchical RL experiments in tensegrity env
