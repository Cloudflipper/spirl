{"train_hl_policy_loss":0.6817620992660522,"_runtime":1667.095054293,"train_top burner":0,"train_hl_policy_entropy":0.8385629653930664,"train_hl_alpha_loss":2.8832640647888184,"_timestamp":1.7310466067336538e+09,"train_bottom burner":0,"train_hinge cabinet":0,"_wandb":{"runtime":1707},"train_slide cabinet":0,"_step":28831,"train_episode_reward":1,"train_hl_critic_loss_2":0.04318620637059212,"train_hl_critic_loss_1":0.03937334939837456,"train_hl_q_2":-0.8249380588531494,"train_hl_prior_divergence":0.06344743818044662,"train_hl_q_target":-0.8293915390968323,"train_hl_q_1":-0.849361002445221,"train_hl_pi_log_prob":0.062241241335868835,"train_microwave":0,"train_hl_target_divergence":5,"train_light switch":0,"train_kettle":1,"train_hl_alpha":0.5839189291000366,"train_episode_length":280}