/home/zzz/spirl-master/spirl/modules/layers.py:12: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.
  nn.init.xavier_normal(m.weight.data)
Reading configurations for Franka
[40m[97mInitializing Franka sim[0m
load datafile: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 26.25it/s]
len train dataset 12325
Reading configurations for Franka
[40m[97mInitializing Franka sim[0m
load datafile: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 31.98it/s]
len val dataset 160
Running Testing
Eval time for batch:  3.5727124214172363
mse: 0.1301497303065844
/home/zzz/spirl-master/spirl/utils/vis_utils.py:25: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.
  plt.xlim(0, array.shape[0] - 1)
val 0: logging videos

Test set: Average loss: 16.1559 in 4.15s

starting epoch  0
/home/zzz/spirl-master/spirl/utils/pytorch_utils.py:339: UserWarning: This overload of addcmul_ is deprecated:
	addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
	addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
train 0: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 0 Train Epoch: 0 [0/4800 (0%)]	Loss: 63.316589
avg time for loading: 0.62s, logs: 0.19s, compute: 0.25s, total: 1.06s
ETA: 141.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167024. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167024. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167024. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167024. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167024. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167024. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167024. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167025. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167025. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167025. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167025. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167025. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 500 Train Epoch: 0 [500/4800 (10%)]	Loss: 2.636196
avg time for loading: 0.03s, logs: 0.00s, compute: 0.10s, total: 0.13s
ETA: 16.73h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 1000 Train Epoch: 0 [1000/4800 (21%)]	Loss: -0.314786
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 16.27h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 1500 Train Epoch: 0 [1500/4800 (31%)]	Loss: -0.690924
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 16.00h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 2000 Train Epoch: 0 [2000/4800 (42%)]	Loss: 1.013377
avg time for loading: 0.02s, logs: 0.00s, compute: 0.09s, total: 0.12s
ETA: 15.77h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 2500 Train Epoch: 0 [2500/4800 (52%)]	Loss: 1.975641
avg time for loading: 0.02s, logs: 0.00s, compute: 0.09s, total: 0.12s
ETA: 15.69h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 3000 Train Epoch: 0 [3000/4800 (62%)]	Loss: 2.617520
avg time for loading: 0.02s, logs: 0.00s, compute: 0.09s, total: 0.12s
ETA: 15.62h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 3500 Train Epoch: 0 [3500/4800 (73%)]	Loss: 3.407283
avg time for loading: 0.02s, logs: 0.00s, compute: 0.09s, total: 0.12s
ETA: 15.62h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 4000 Train Epoch: 0 [4000/4800 (83%)]	Loss: 4.595373
avg time for loading: 0.02s, logs: 0.00s, compute: 0.09s, total: 0.12s
ETA: 15.55h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4000 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 4500 Train Epoch: 0 [4500/4800 (94%)]	Loss: 4.663336
avg time for loading: 0.02s, logs: 0.00s, compute: 0.09s, total: 0.12s
ETA: 15.49h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4500 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep0.pth!
Running Testing
Eval time for batch:  3.5181498527526855
mse: 0.029279623598995386
val 4800: logging videos

Test set: Average loss: 5.1801 in 3.96s

starting epoch  1
train 4800: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 4800 Train Epoch: 1 [0/4800 (0%)]	Loss: 5.242021
avg time for loading: 0.63s, logs: 0.20s, compute: 0.21s, total: 1.04s
ETA: 137.33h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167026. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167027. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167027. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167027. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167027. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167027. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 5000 Train Epoch: 1 [200/4800 (4%)]	Loss: 5.756814
avg time for loading: 0.02s, logs: 0.00s, compute: 0.09s, total: 0.12s
ETA: 15.64h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 5500 Train Epoch: 1 [700/4800 (15%)]	Loss: 5.800565
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 15.86h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 6000 Train Epoch: 1 [1200/4800 (25%)]	Loss: 7.110287
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 15.90h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 6500 Train Epoch: 1 [1700/4800 (35%)]	Loss: 6.745047
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 15.91h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 7000 Train Epoch: 1 [2200/4800 (46%)]	Loss: 6.553185
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 16.10h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 7500 Train Epoch: 1 [2700/4800 (56%)]	Loss: 6.456503
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 16.13h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 8000 Train Epoch: 1 [3200/4800 (67%)]	Loss: 7.279866
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 16.14h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 8500 Train Epoch: 1 [3700/4800 (77%)]	Loss: 6.558793
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 16.14h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 9000 Train Epoch: 1 [4200/4800 (88%)]	Loss: 7.576952
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 16.00h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9000 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 9500 Train Epoch: 1 [4700/4800 (98%)]	Loss: 7.573356
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 15.93h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9500 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep1.pth!
starting epoch  2
train 9600: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 9600 Train Epoch: 2 [0/4800 (0%)]	Loss: 7.490511
avg time for loading: 0.64s, logs: 0.36s, compute: 0.23s, total: 1.24s
ETA: 161.73h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9600 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9600 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9600 that is less than the current step 167028. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9600 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9600 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9600 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9600 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 10000 Train Epoch: 2 [400/4800 (8%)]	Loss: 8.052585
avg time for loading: 0.02s, logs: 0.00s, compute: 0.09s, total: 0.11s
ETA: 14.80h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 10500 Train Epoch: 2 [900/4800 (19%)]	Loss: 7.599441
avg time for loading: 0.02s, logs: 0.00s, compute: 0.07s, total: 0.09s
ETA: 11.49h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 11000 Train Epoch: 2 [1400/4800 (29%)]	Loss: 7.305691
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.97h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 11500 Train Epoch: 2 [1900/4800 (40%)]	Loss: 7.960970
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.70h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 12000 Train Epoch: 2 [2400/4800 (50%)]	Loss: 7.447617
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.53h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 12500 Train Epoch: 2 [2900/4800 (60%)]	Loss: 7.603361
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.45h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 13000 Train Epoch: 2 [3400/4800 (71%)]	Loss: 7.968148
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.40h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 13500 Train Epoch: 2 [3900/4800 (81%)]	Loss: 7.872165
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.35h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13500 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 14000 Train Epoch: 2 [4400/4800 (92%)]	Loss: 7.939742
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.36h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14000 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep2.pth!
starting epoch  3
train 14400: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 14400 Train Epoch: 3 [0/4800 (0%)]	Loss: 8.278063
avg time for loading: 0.54s, logs: 0.15s, compute: 0.11s, total: 0.80s
ETA: 102.89h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14400 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14400 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14400 that is less than the current step 167029. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14400 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14400 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14400 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14400 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 14500 Train Epoch: 3 [100/4800 (2%)]	Loss: 8.441100
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 11.25h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 15000 Train Epoch: 3 [600/4800 (12%)]	Loss: 8.421822
avg time for loading: 0.03s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 10.19h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 15500 Train Epoch: 3 [1100/4800 (23%)]	Loss: 8.658140
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 10.04h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 16000 Train Epoch: 3 [1600/4800 (33%)]	Loss: 9.057193
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 10.02h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 16500 Train Epoch: 3 [2100/4800 (44%)]	Loss: 8.358451
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 10.00h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 17000 Train Epoch: 3 [2600/4800 (54%)]	Loss: 9.129208
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.99h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 17500 Train Epoch: 3 [3100/4800 (65%)]	Loss: 8.561044
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.97h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 18000 Train Epoch: 3 [3600/4800 (75%)]	Loss: 8.410525
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.95h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 18500 Train Epoch: 3 [4100/4800 (85%)]	Loss: 9.325430
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.93h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18500 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 19000 Train Epoch: 3 [4600/4800 (96%)]	Loss: 8.534184
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.93h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19000 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep3.pth!
starting epoch  4
train 19200: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 19200 Train Epoch: 4 [0/4800 (0%)]	Loss: 8.568719
avg time for loading: 0.54s, logs: 0.14s, compute: 0.12s, total: 0.79s
ETA: 101.15h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19200 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19200 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19200 that is less than the current step 167030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19200 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19200 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19200 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19200 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 19500 Train Epoch: 4 [300/4800 (6%)]	Loss: 8.747098
avg time for loading: 0.03s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 10.12h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 20000 Train Epoch: 4 [800/4800 (17%)]	Loss: 8.816647
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.92h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 20500 Train Epoch: 4 [1300/4800 (27%)]	Loss: 9.389475
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.84h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 21000 Train Epoch: 4 [1800/4800 (38%)]	Loss: 9.117816
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.84h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 21500 Train Epoch: 4 [2300/4800 (48%)]	Loss: 9.048452
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.83h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 22000 Train Epoch: 4 [2800/4800 (58%)]	Loss: 9.629135
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.85h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 22500 Train Epoch: 4 [3300/4800 (69%)]	Loss: 8.425311
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.85h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 23000 Train Epoch: 4 [3800/4800 (79%)]	Loss: 8.431863
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.85h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 23500 Train Epoch: 4 [4300/4800 (90%)]	Loss: 9.095243
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.86h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23500 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep4.pth!
starting epoch  5
train 24000: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 24000 Train Epoch: 5 [0/4800 (0%)]	Loss: 8.966475
avg time for loading: 0.57s, logs: 0.13s, compute: 0.11s, total: 0.81s
ETA: 102.74h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24000 that is less than the current step 167031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 24500 Train Epoch: 5 [500/4800 (10%)]	Loss: 8.741952
avg time for loading: 0.03s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 10.19h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 25000 Train Epoch: 5 [1000/4800 (21%)]	Loss: 9.205794
avg time for loading: 0.03s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 10.06h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 25500 Train Epoch: 5 [1500/4800 (31%)]	Loss: 9.319964
avg time for loading: 0.03s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 10.09h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 26000 Train Epoch: 5 [2000/4800 (42%)]	Loss: 9.317840
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 10.06h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 26500 Train Epoch: 5 [2500/4800 (52%)]	Loss: 9.295656
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 10.03h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 27000 Train Epoch: 5 [3000/4800 (62%)]	Loss: 8.599234
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.99h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 27500 Train Epoch: 5 [3500/4800 (73%)]	Loss: 9.663474
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.96h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 28000 Train Epoch: 5 [4000/4800 (83%)]	Loss: 8.863826
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.95h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28000 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 28500 Train Epoch: 5 [4500/4800 (94%)]	Loss: 8.833884
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.97h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28500 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep5.pth!
Running Testing
Eval time for batch:  2.133270740509033
mse: 0.015692756092903437
val 28800: logging videos

Test set: Average loss: 10.5074 in 2.51s

starting epoch  6
train 28800: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 28800 Train Epoch: 6 [0/4800 (0%)]	Loss: 9.631881
avg time for loading: 0.60s, logs: 0.16s, compute: 0.13s, total: 0.89s
ETA: 111.77h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167032. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167033. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167033. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167033. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167033. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167033. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 29000 Train Epoch: 6 [200/4800 (4%)]	Loss: 9.176218
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.43h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 29500 Train Epoch: 6 [700/4800 (15%)]	Loss: 8.913479
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.00h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 30000 Train Epoch: 6 [1200/4800 (25%)]	Loss: 9.458104
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.92h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 30500 Train Epoch: 6 [1700/4800 (35%)]	Loss: 9.471197
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.84h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 31000 Train Epoch: 6 [2200/4800 (46%)]	Loss: 9.529277
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.94h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 31500 Train Epoch: 6 [2700/4800 (56%)]	Loss: 8.953086
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.94h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 32000 Train Epoch: 6 [3200/4800 (67%)]	Loss: 9.661518
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.93h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 32500 Train Epoch: 6 [3700/4800 (77%)]	Loss: 8.741572
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.95h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 33000 Train Epoch: 6 [4200/4800 (88%)]	Loss: 9.012757
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.95h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33000 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 33500 Train Epoch: 6 [4700/4800 (98%)]	Loss: 9.517815
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.96h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33500 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep6.pth!
starting epoch  7
train 33600: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 33600 Train Epoch: 7 [0/4800 (0%)]	Loss: 9.129955
avg time for loading: 0.54s, logs: 0.14s, compute: 0.12s, total: 0.80s
ETA: 99.06h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33600 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33600 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33600 that is less than the current step 167034. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33600 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33600 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33600 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33600 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 34000 Train Epoch: 7 [400/4800 (8%)]	Loss: 9.492110
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.52h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 34500 Train Epoch: 7 [900/4800 (19%)]	Loss: 9.176291
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.24h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 35000 Train Epoch: 7 [1400/4800 (29%)]	Loss: 9.526363
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.13h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 35500 Train Epoch: 7 [1900/4800 (40%)]	Loss: 9.673923
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.07h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 36000 Train Epoch: 7 [2400/4800 (50%)]	Loss: 9.784894
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.05h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 36500 Train Epoch: 7 [2900/4800 (60%)]	Loss: 9.855631
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.00h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 37000 Train Epoch: 7 [3400/4800 (71%)]	Loss: 9.420062
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.01h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 37500 Train Epoch: 7 [3900/4800 (81%)]	Loss: 9.242687
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.98h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37500 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 38000 Train Epoch: 7 [4400/4800 (92%)]	Loss: 9.459762
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.97h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38000 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep7.pth!
starting epoch  8
train 38400: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 38400 Train Epoch: 8 [0/4800 (0%)]	Loss: 9.568464
avg time for loading: 0.62s, logs: 0.17s, compute: 0.15s, total: 0.95s
ETA: 116.14h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38400 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38400 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38400 that is less than the current step 167035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38400 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38400 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38400 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38400 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 38500 Train Epoch: 8 [100/4800 (2%)]	Loss: 9.616068
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 11.17h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 38500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 39000 Train Epoch: 8 [600/4800 (12%)]	Loss: 9.445316
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.82h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 39500 Train Epoch: 8 [1100/4800 (23%)]	Loss: 9.091004
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.69h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 39500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 40000 Train Epoch: 8 [1600/4800 (33%)]	Loss: 10.736786
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.76h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 40500 Train Epoch: 8 [2100/4800 (44%)]	Loss: 9.381570
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.76h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 40500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 41000 Train Epoch: 8 [2600/4800 (54%)]	Loss: 10.163815
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.79h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 41500 Train Epoch: 8 [3100/4800 (65%)]	Loss: 9.169753
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.78h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 41500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 42000 Train Epoch: 8 [3600/4800 (75%)]	Loss: 9.354714
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.82h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 42500 Train Epoch: 8 [4100/4800 (85%)]	Loss: 9.533499
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.83h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 42500 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 43000 Train Epoch: 8 [4600/4800 (96%)]	Loss: 9.656335
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.82h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43000 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep8.pth!
starting epoch  9
train 43200: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 43200 Train Epoch: 9 [0/4800 (0%)]	Loss: 9.266961
avg time for loading: 0.58s, logs: 0.15s, compute: 0.11s, total: 0.84s
ETA: 102.39h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43200 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43200 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43200 that is less than the current step 167036. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43200 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43200 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43200 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43200 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 43500 Train Epoch: 9 [300/4800 (6%)]	Loss: 9.665036
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.15h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 43500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 44000 Train Epoch: 9 [800/4800 (17%)]	Loss: 9.515251
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 10.39h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 44500 Train Epoch: 9 [1300/4800 (27%)]	Loss: 10.563606
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.06h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 44500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 45000 Train Epoch: 9 [1800/4800 (38%)]	Loss: 9.254919
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.91h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 45500 Train Epoch: 9 [2300/4800 (48%)]	Loss: 9.477453
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.82h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 45500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 46000 Train Epoch: 9 [2800/4800 (58%)]	Loss: 9.539178
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.79h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 46500 Train Epoch: 9 [3300/4800 (69%)]	Loss: 9.829627
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.80h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 46500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 47000 Train Epoch: 9 [3800/4800 (79%)]	Loss: 9.363758
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.78h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 47500 Train Epoch: 9 [4300/4800 (90%)]	Loss: 9.669722
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.75h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 47500 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep9.pth!
starting epoch  10
train 48000: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 48000 Train Epoch: 10 [0/4800 (0%)]	Loss: 9.103985
avg time for loading: 0.63s, logs: 0.17s, compute: 0.15s, total: 0.96s
ETA: 115.30h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48000 that is less than the current step 167037. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 48500 Train Epoch: 10 [500/4800 (10%)]	Loss: 10.000334
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.00h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 48500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 49000 Train Epoch: 10 [1000/4800 (21%)]	Loss: 10.213973
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.70h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 49500 Train Epoch: 10 [1500/4800 (31%)]	Loss: 9.438283
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.60h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 49500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 50000 Train Epoch: 10 [2000/4800 (42%)]	Loss: 9.829124
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.56h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 50500 Train Epoch: 10 [2500/4800 (52%)]	Loss: 9.950098
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.56h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 50500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 51000 Train Epoch: 10 [3000/4800 (62%)]	Loss: 10.163228
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.52h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 51500 Train Epoch: 10 [3500/4800 (73%)]	Loss: 9.612592
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 51500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 52000 Train Epoch: 10 [4000/4800 (83%)]	Loss: 9.756861
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52000 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 52500 Train Epoch: 10 [4500/4800 (94%)]	Loss: 9.585239
avg time for loading: 0.02s, logs: 0.00s, compute: 0.05s, total: 0.08s
ETA: 9.53h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52500 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep10.pth!
Running Testing
Eval time for batch:  2.0000977516174316
mse: 0.01319151686038822
val 52800: logging videos

Test set: Average loss: 11.3671 in 2.60s

starting epoch  11
train 52800: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 52800 Train Epoch: 11 [0/4800 (0%)]	Loss: 9.681911
avg time for loading: 0.62s, logs: 0.16s, compute: 0.17s, total: 0.94s
ETA: 112.02h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167039. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167039. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167039. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167039. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167039. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 52800 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 53000 Train Epoch: 11 [200/4800 (4%)]	Loss: 10.507231
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 10.06h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 53500 Train Epoch: 11 [700/4800 (15%)]	Loss: 9.875901
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.64h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 53500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 54000 Train Epoch: 11 [1200/4800 (25%)]	Loss: 9.656189
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.58h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 54500 Train Epoch: 11 [1700/4800 (35%)]	Loss: 9.424644
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.79h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 54500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 55000 Train Epoch: 11 [2200/4800 (46%)]	Loss: 9.422727
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.74h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 55500 Train Epoch: 11 [2700/4800 (56%)]	Loss: 9.534981
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.77h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 55500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 56000 Train Epoch: 11 [3200/4800 (67%)]	Loss: 9.379948
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 10.64h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 56500 Train Epoch: 11 [3700/4800 (77%)]	Loss: 9.698649
avg time for loading: 0.02s, logs: 0.00s, compute: 0.07s, total: 0.10s
ETA: 11.33h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 56500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 57000 Train Epoch: 11 [4200/4800 (88%)]	Loss: 9.390790
avg time for loading: 0.02s, logs: 0.00s, compute: 0.07s, total: 0.10s
ETA: 11.68h
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 57500 Train Epoch: 11 [4700/4800 (98%)]	Loss: 9.861071
avg time for loading: 0.02s, logs: 0.00s, compute: 0.08s, total: 0.10s
ETA: 11.93h
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep11.pth!
starting epoch  12
train 57600: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 57600 Train Epoch: 12 [0/4800 (0%)]	Loss: 9.832735
avg time for loading: 0.83s, logs: 0.21s, compute: 0.22s, total: 1.26s
ETA: 147.28h
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 58000 Train Epoch: 12 [400/4800 (8%)]	Loss: 9.694198
avg time for loading: 0.02s, logs: 0.00s, compute: 0.12s, total: 0.14s
ETA: 16.39h
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 58500 Train Epoch: 12 [900/4800 (19%)]	Loss: 9.835168
avg time for loading: 0.02s, logs: 0.00s, compute: 0.13s, total: 0.15s
ETA: 17.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57000 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57500 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57600 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57600 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57600 that is less than the current step 167040. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57600 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57600 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57600 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 57600 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 58500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 59000 Train Epoch: 12 [1400/4800 (29%)]	Loss: 9.562551
avg time for loading: 0.02s, logs: 0.00s, compute: 0.13s, total: 0.15s
ETA: 17.39h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 59500 Train Epoch: 12 [1900/4800 (40%)]	Loss: 10.083652
avg time for loading: 0.02s, logs: 0.00s, compute: 0.13s, total: 0.15s
ETA: 17.81h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 59500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 60000 Train Epoch: 12 [2400/4800 (50%)]	Loss: 10.030656
avg time for loading: 0.02s, logs: 0.00s, compute: 0.13s, total: 0.15s
ETA: 17.33h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 60500 Train Epoch: 12 [2900/4800 (60%)]	Loss: 9.985530
avg time for loading: 0.02s, logs: 0.00s, compute: 0.12s, total: 0.14s
ETA: 16.72h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 60500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 61000 Train Epoch: 12 [3400/4800 (71%)]	Loss: 9.524993
avg time for loading: 0.02s, logs: 0.00s, compute: 0.12s, total: 0.14s
ETA: 16.28h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 61500 Train Epoch: 12 [3900/4800 (81%)]	Loss: 9.971849
avg time for loading: 0.02s, logs: 0.00s, compute: 0.12s, total: 0.14s
ETA: 15.95h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 61500 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 62000 Train Epoch: 12 [4400/4800 (92%)]	Loss: 9.706466
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 15.67h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62000 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep12.pth!
starting epoch  13
train 62400: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 62400 Train Epoch: 13 [0/4800 (0%)]	Loss: 9.946747
avg time for loading: 0.83s, logs: 0.24s, compute: 0.30s, total: 1.37s
ETA: 159.23h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62400 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62400 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62400 that is less than the current step 167041. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62400 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62400 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62400 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62400 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 62500 Train Epoch: 13 [100/4800 (2%)]	Loss: 10.777774
avg time for loading: 0.03s, logs: 0.00s, compute: 0.11s, total: 0.14s
ETA: 16.19h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 62500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 63000 Train Epoch: 13 [600/4800 (12%)]	Loss: 10.074656
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 14.04h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 63500 Train Epoch: 13 [1100/4800 (23%)]	Loss: 9.401021
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 13.84h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 63500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 64000 Train Epoch: 13 [1600/4800 (33%)]	Loss: 10.270369
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 13.77h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 64500 Train Epoch: 13 [2100/4800 (44%)]	Loss: 9.805543
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 13.68h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 64500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 65000 Train Epoch: 13 [2600/4800 (54%)]	Loss: 9.401550
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 14.04h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 65500 Train Epoch: 13 [3100/4800 (65%)]	Loss: 9.551579
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.86h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 65500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 66000 Train Epoch: 13 [3600/4800 (75%)]	Loss: 10.192298
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 15.14h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 66500 Train Epoch: 13 [4100/4800 (85%)]	Loss: 9.920255
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.99h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 66500 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 67000 Train Epoch: 13 [4600/4800 (96%)]	Loss: 9.684497
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 15.01h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67000 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep13.pth!
starting epoch  14
train 67200: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 67200 Train Epoch: 14 [0/4800 (0%)]	Loss: 9.869738
avg time for loading: 0.96s, logs: 0.32s, compute: 0.33s, total: 1.61s
ETA: 184.18h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67200 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67200 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67200 that is less than the current step 167042. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67200 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67200 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67200 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67200 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 67500 Train Epoch: 14 [300/4800 (6%)]	Loss: 10.159441
avg time for loading: 0.02s, logs: 0.00s, compute: 0.12s, total: 0.14s
ETA: 16.36h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 67500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 68000 Train Epoch: 14 [800/4800 (17%)]	Loss: 9.486124
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.80h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 68500 Train Epoch: 14 [1300/4800 (27%)]	Loss: 10.594464
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.54h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 68500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 69000 Train Epoch: 14 [1800/4800 (38%)]	Loss: 9.953197
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.52h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 69500 Train Epoch: 14 [2300/4800 (48%)]	Loss: 9.721931
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 69500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 70000 Train Epoch: 14 [2800/4800 (58%)]	Loss: 10.446936
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.67h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 70500 Train Epoch: 14 [3300/4800 (69%)]	Loss: 10.147606
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.54h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 70500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 71000 Train Epoch: 14 [3800/4800 (79%)]	Loss: 9.410491
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.77h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 71500 Train Epoch: 14 [4300/4800 (90%)]	Loss: 9.892673
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.75h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 71500 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep14.pth!
starting epoch  15
train 72000: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 72000 Train Epoch: 15 [0/4800 (0%)]	Loss: 9.806732
avg time for loading: 1.05s, logs: 0.28s, compute: 0.29s, total: 1.61s
ETA: 182.85h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72000 that is less than the current step 167043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 72500 Train Epoch: 15 [500/4800 (10%)]	Loss: 10.117224
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.96h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 72500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 73000 Train Epoch: 15 [1000/4800 (21%)]	Loss: 10.016830
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 73500 Train Epoch: 15 [1500/4800 (31%)]	Loss: 9.395457
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.25h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 73500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 74000 Train Epoch: 15 [2000/4800 (42%)]	Loss: 10.194392
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.21h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 74500 Train Epoch: 15 [2500/4800 (52%)]	Loss: 9.955443
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.33h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 74500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 75000 Train Epoch: 15 [3000/4800 (62%)]	Loss: 10.093468
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.41h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 75500 Train Epoch: 15 [3500/4800 (73%)]	Loss: 9.790213
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.39h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 75500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 76000 Train Epoch: 15 [4000/4800 (83%)]	Loss: 10.188973
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.26h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76000 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 76500 Train Epoch: 15 [4500/4800 (94%)]	Loss: 10.112824
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.27h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76500 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep15.pth!
Running Testing
Eval time for batch:  4.286383152008057
mse: 0.01129476827372855
val 76800: logging videos

Test set: Average loss: 12.1273 in 5.05s

starting epoch  16
train 76800: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 76800 Train Epoch: 16 [0/4800 (0%)]	Loss: 9.791878
avg time for loading: 0.89s, logs: 0.25s, compute: 0.27s, total: 1.41s
ETA: 157.95h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167044. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167045. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167045. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167045. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167045. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167045. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 76800 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 77000 Train Epoch: 16 [200/4800 (4%)]	Loss: 10.320988
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.13s
ETA: 14.43h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 77500 Train Epoch: 16 [700/4800 (15%)]	Loss: 10.266563
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.13s
ETA: 14.16h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 77500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 78000 Train Epoch: 16 [1200/4800 (25%)]	Loss: 10.240049
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 13.62h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 78500 Train Epoch: 16 [1700/4800 (35%)]	Loss: 10.577030
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 13.57h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 78500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 79000 Train Epoch: 16 [2200/4800 (46%)]	Loss: 9.421220
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 13.52h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 79500 Train Epoch: 16 [2700/4800 (56%)]	Loss: 10.599519
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 13.59h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 79500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 80000 Train Epoch: 16 [3200/4800 (67%)]	Loss: 10.348921
avg time for loading: 0.02s, logs: 0.00s, compute: 0.10s, total: 0.12s
ETA: 13.58h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 80500 Train Epoch: 16 [3700/4800 (77%)]	Loss: 10.045074
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.36h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 80500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 81000 Train Epoch: 16 [4200/4800 (88%)]	Loss: 10.013466
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.28h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81000 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 81500 Train Epoch: 16 [4700/4800 (98%)]	Loss: 10.209414
avg time for loading: 0.02s, logs: 0.00s, compute: 0.11s, total: 0.13s
ETA: 14.25h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81500 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep16.pth!
starting epoch  17
train 81600: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 81600 Train Epoch: 17 [0/4800 (0%)]	Loss: 10.284307
avg time for loading: 0.94s, logs: 0.26s, compute: 0.36s, total: 1.56s
ETA: 173.00h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81600 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81600 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81600 that is less than the current step 167046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81600 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81600 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81600 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 81600 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 82000 Train Epoch: 17 [400/4800 (8%)]	Loss: 10.271445
avg time for loading: 0.02s, logs: 0.00s, compute: 3.05s, total: 3.07s
ETA: 339.99h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 82500 Train Epoch: 17 [900/4800 (19%)]	Loss: 10.199010
avg time for loading: 0.02s, logs: 0.00s, compute: 1.40s, total: 1.42s
ETA: 156.98h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 82500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 83000 Train Epoch: 17 [1400/4800 (29%)]	Loss: 9.433395
avg time for loading: 0.02s, logs: 0.00s, compute: 0.92s, total: 0.94s
ETA: 104.27h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 83500 Train Epoch: 17 [1900/4800 (40%)]	Loss: 10.491331
avg time for loading: 0.02s, logs: 0.00s, compute: 0.70s, total: 0.72s
ETA: 79.35h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 83500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 84000 Train Epoch: 17 [2400/4800 (50%)]	Loss: 10.115740
avg time for loading: 0.02s, logs: 0.00s, compute: 0.56s, total: 0.58s
ETA: 64.73h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 84500 Train Epoch: 17 [2900/4800 (60%)]	Loss: 9.795732
avg time for loading: 0.02s, logs: 0.00s, compute: 0.48s, total: 0.50s
ETA: 55.16h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 84500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 85000 Train Epoch: 17 [3400/4800 (71%)]	Loss: 9.929127
avg time for loading: 0.02s, logs: 0.00s, compute: 0.41s, total: 0.44s
ETA: 48.39h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 85500 Train Epoch: 17 [3900/4800 (81%)]	Loss: 9.989159
avg time for loading: 0.02s, logs: 0.00s, compute: 0.37s, total: 0.39s
ETA: 43.37h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 85500 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 86000 Train Epoch: 17 [4400/4800 (92%)]	Loss: 10.214438
avg time for loading: 0.02s, logs: 0.00s, compute: 0.33s, total: 0.36s
ETA: 39.46h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86000 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep17.pth!
starting epoch  18
train 86400: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 86400 Train Epoch: 18 [0/4800 (0%)]	Loss: 9.701699
avg time for loading: 0.81s, logs: 0.23s, compute: 0.18s, total: 1.21s
ETA: 132.12h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86400 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86400 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86400 that is less than the current step 167047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86400 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86400 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86400 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86400 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 86500 Train Epoch: 18 [100/4800 (2%)]	Loss: 10.013860
avg time for loading: 0.03s, logs: 0.00s, compute: 0.07s, total: 0.10s
ETA: 11.35h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 86500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 87000 Train Epoch: 18 [600/4800 (12%)]	Loss: 10.654918
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 9.31h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 87500 Train Epoch: 18 [1100/4800 (23%)]	Loss: 10.262137
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.03h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 87500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 88000 Train Epoch: 18 [1600/4800 (33%)]	Loss: 9.804532
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.00h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 88500 Train Epoch: 18 [2100/4800 (44%)]	Loss: 10.383193
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.99h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 88500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 89000 Train Epoch: 18 [2600/4800 (54%)]	Loss: 9.889916
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 9.02h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 89500 Train Epoch: 18 [3100/4800 (65%)]	Loss: 10.347063
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.96h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 89500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 90000 Train Epoch: 18 [3600/4800 (75%)]	Loss: 10.755466
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.95h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 90500 Train Epoch: 18 [4100/4800 (85%)]	Loss: 10.056165
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.91h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 90500 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 91000 Train Epoch: 18 [4600/4800 (96%)]	Loss: 10.102281
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.89h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91000 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep18.pth!
starting epoch  19
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91200 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91200 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91200 that is less than the current step 167048. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
train 91200: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 91200 Train Epoch: 19 [0/4800 (0%)]	Loss: 10.178327
avg time for loading: 0.74s, logs: 0.18s, compute: 0.14s, total: 1.06s
ETA: 114.32h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91200 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91200 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91200 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91200 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 91500 Train Epoch: 19 [300/4800 (6%)]	Loss: 10.128542
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 9.22h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 91500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 92000 Train Epoch: 19 [800/4800 (17%)]	Loss: 9.850743
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.85h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 92500 Train Epoch: 19 [1300/4800 (27%)]	Loss: 9.885249
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.73h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 92500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 93000 Train Epoch: 19 [1800/4800 (38%)]	Loss: 10.234043
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.85h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 93500 Train Epoch: 19 [2300/4800 (48%)]	Loss: 10.263319
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.86h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 93500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 94000 Train Epoch: 19 [2800/4800 (58%)]	Loss: 10.417689
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.81h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 94500 Train Epoch: 19 [3300/4800 (69%)]	Loss: 10.148007
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.81h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 94500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 95000 Train Epoch: 19 [3800/4800 (79%)]	Loss: 10.318101
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.78h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 95500 Train Epoch: 19 [4300/4800 (90%)]	Loss: 9.798194
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.73h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 95500 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep19.pth!
starting epoch  20
train 96000: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 96000 Train Epoch: 20 [0/4800 (0%)]	Loss: 10.217163
avg time for loading: 0.72s, logs: 0.20s, compute: 0.18s, total: 1.10s
ETA: 117.19h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96000 that is less than the current step 167049. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 96500 Train Epoch: 20 [500/4800 (10%)]	Loss: 10.337207
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 9.13h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 96500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 97000 Train Epoch: 20 [1000/4800 (21%)]	Loss: 10.280705
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.91h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 97500 Train Epoch: 20 [1500/4800 (31%)]	Loss: 10.166266
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.75h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 97500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 98000 Train Epoch: 20 [2000/4800 (42%)]	Loss: 10.419681
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.69h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 98500 Train Epoch: 20 [2500/4800 (52%)]	Loss: 9.671659
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.66h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 98500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 99000 Train Epoch: 20 [3000/4800 (62%)]	Loss: 10.680962
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.67h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 99500 Train Epoch: 20 [3500/4800 (73%)]	Loss: 10.598360
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.66h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 99500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 100000 Train Epoch: 20 [4000/4800 (83%)]	Loss: 10.077845
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.67h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100000 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 100500 Train Epoch: 20 [4500/4800 (94%)]	Loss: 10.068339
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.63h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100500 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep20.pth!
Running Testing
Eval time for batch:  2.5160937309265137
mse: 0.009471151641264441
val 100800: logging videos

Test set: Average loss: 11.7552 in 3.13s

starting epoch  21
train 100800: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 100800 Train Epoch: 21 [0/4800 (0%)]	Loss: 10.137218
avg time for loading: 0.66s, logs: 0.15s, compute: 0.12s, total: 0.93s
ETA: 97.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167050. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167051. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167051. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167051. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167051. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167051. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 100800 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 101000 Train Epoch: 21 [200/4800 (4%)]	Loss: 10.091580
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.86h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 101500 Train Epoch: 21 [700/4800 (15%)]	Loss: 10.469147
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.79h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 101500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 102000 Train Epoch: 21 [1200/4800 (25%)]	Loss: 10.636019
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.57h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 102500 Train Epoch: 21 [1700/4800 (35%)]	Loss: 10.291767
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.53h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 102500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 103000 Train Epoch: 21 [2200/4800 (46%)]	Loss: 10.412007
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.54h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 103500 Train Epoch: 21 [2700/4800 (56%)]	Loss: 10.527861
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 103500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 104000 Train Epoch: 21 [3200/4800 (67%)]	Loss: 9.975167
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.47h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 104500 Train Epoch: 21 [3700/4800 (77%)]	Loss: 10.492350
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.50h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 104500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 105000 Train Epoch: 21 [4200/4800 (88%)]	Loss: 10.112179
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105000 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 105500 Train Epoch: 21 [4700/4800 (98%)]	Loss: 10.116737
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.53h
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep21.pth!
starting epoch  22
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105500 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
train 105600: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 105600 Train Epoch: 22 [0/4800 (0%)]	Loss: 10.018919
avg time for loading: 0.79s, logs: 0.19s, compute: 0.18s, total: 1.15s
ETA: 119.96h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105600 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105600 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105600 that is less than the current step 167052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105600 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105600 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105600 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 105600 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 106000 Train Epoch: 22 [400/4800 (8%)]	Loss: 10.381182
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 9.01h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 106500 Train Epoch: 22 [900/4800 (19%)]	Loss: 9.841338
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.74h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 106500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 107000 Train Epoch: 22 [1400/4800 (29%)]	Loss: 10.318480
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 107500 Train Epoch: 22 [1900/4800 (40%)]	Loss: 10.224454
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.52h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 107500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 108000 Train Epoch: 22 [2400/4800 (50%)]	Loss: 10.302227
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 108500 Train Epoch: 22 [2900/4800 (60%)]	Loss: 10.129693
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.49h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 108500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 109000 Train Epoch: 22 [3400/4800 (71%)]	Loss: 9.810628
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.52h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 109500 Train Epoch: 22 [3900/4800 (81%)]	Loss: 10.551108
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.56h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 109500 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 110000 Train Epoch: 22 [4400/4800 (92%)]	Loss: 10.947561
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.60h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110000 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep22.pth!
starting epoch  23
train 110400: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 110400 Train Epoch: 23 [0/4800 (0%)]	Loss: 10.472397
avg time for loading: 0.91s, logs: 0.21s, compute: 0.14s, total: 1.26s
ETA: 129.64h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110400 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110400 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110400 that is less than the current step 167053. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110400 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110400 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110400 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110400 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 110500 Train Epoch: 23 [100/4800 (2%)]	Loss: 9.867727
avg time for loading: 0.03s, logs: 0.00s, compute: 0.07s, total: 0.10s
ETA: 10.76h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 110500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 111000 Train Epoch: 23 [600/4800 (12%)]	Loss: 9.874356
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 9.07h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 111500 Train Epoch: 23 [1100/4800 (23%)]	Loss: 10.611615
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.71h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 111500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 112000 Train Epoch: 23 [1600/4800 (33%)]	Loss: 10.623801
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.59h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 112500 Train Epoch: 23 [2100/4800 (44%)]	Loss: 10.045935
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.56h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 112500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 113000 Train Epoch: 23 [2600/4800 (54%)]	Loss: 9.960255
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.47h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 113500 Train Epoch: 23 [3100/4800 (65%)]	Loss: 10.192707
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.46h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 113500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 114000 Train Epoch: 23 [3600/4800 (75%)]	Loss: 10.372796
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.43h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 114500 Train Epoch: 23 [4100/4800 (85%)]	Loss: 10.915257
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.39h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 114500 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 115000 Train Epoch: 23 [4600/4800 (96%)]	Loss: 10.013269
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.38h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115000 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep23.pth!
starting epoch  24
train 115200: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 115200 Train Epoch: 24 [0/4800 (0%)]	Loss: 10.522463
avg time for loading: 0.82s, logs: 0.18s, compute: 0.15s, total: 1.16s
ETA: 117.05h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115200 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115200 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115200 that is less than the current step 167054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115200 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115200 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115200 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115200 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 115500 Train Epoch: 24 [300/4800 (6%)]	Loss: 9.824764
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.58h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 115500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 116000 Train Epoch: 24 [800/4800 (17%)]	Loss: 10.594789
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.20h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 116500 Train Epoch: 24 [1300/4800 (27%)]	Loss: 10.389051
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.23h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 116500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 117000 Train Epoch: 24 [1800/4800 (38%)]	Loss: 10.039650
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.23h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 117500 Train Epoch: 24 [2300/4800 (48%)]	Loss: 10.847314
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.21h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 117500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 118000 Train Epoch: 24 [2800/4800 (58%)]	Loss: 10.412662
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.16h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 118500 Train Epoch: 24 [3300/4800 (69%)]	Loss: 9.894477
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.19h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 118500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 119000 Train Epoch: 24 [3800/4800 (79%)]	Loss: 10.136417
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.26h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 119500 Train Epoch: 24 [4300/4800 (90%)]	Loss: 10.266543
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.26h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 119500 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep24.pth!
starting epoch  25
train 120000: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 120000 Train Epoch: 25 [0/4800 (0%)]	Loss: 10.233869
avg time for loading: 0.94s, logs: 0.18s, compute: 0.16s, total: 1.28s
ETA: 127.95h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120000 that is less than the current step 167055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 120500 Train Epoch: 25 [500/4800 (10%)]	Loss: 9.727157
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 8.57h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 120500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 121000 Train Epoch: 25 [1000/4800 (21%)]	Loss: 10.155867
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.18h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 121500 Train Epoch: 25 [1500/4800 (31%)]	Loss: 9.850194
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.17h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 121500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 122000 Train Epoch: 25 [2000/4800 (42%)]	Loss: 10.115170
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.14h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 122500 Train Epoch: 25 [2500/4800 (52%)]	Loss: 10.567401
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.07h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 122500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 123000 Train Epoch: 25 [3000/4800 (62%)]	Loss: 10.201548
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.07h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 123500 Train Epoch: 25 [3500/4800 (73%)]	Loss: 10.452255
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.09h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 123500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 124000 Train Epoch: 25 [4000/4800 (83%)]	Loss: 10.700183
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.06h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124000 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 124500 Train Epoch: 25 [4500/4800 (94%)]	Loss: 10.131940
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.10h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124500 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep25.pth!
Running Testing
Eval time for batch:  2.7054147720336914
mse: 0.009835775620558707
val 124800: logging videos

Test set: Average loss: 12.4301 in 3.38s

starting epoch  26
train 124800: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 124800 Train Epoch: 26 [0/4800 (0%)]	Loss: 10.560251
avg time for loading: 0.67s, logs: 0.19s, compute: 0.13s, total: 0.99s
ETA: 97.84h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167056. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167057. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167057. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167057. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167057. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167057. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 124800 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 125000 Train Epoch: 26 [200/4800 (4%)]	Loss: 10.384722
avg time for loading: 0.02s, logs: 0.00s, compute: 0.07s, total: 0.09s
ETA: 9.19h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 125500 Train Epoch: 26 [700/4800 (15%)]	Loss: 10.553825
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.22h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 125500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 126000 Train Epoch: 26 [1200/4800 (25%)]	Loss: 10.214052
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 8.45h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 126500 Train Epoch: 26 [1700/4800 (35%)]	Loss: 10.294750
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 8.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 126500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 127000 Train Epoch: 26 [2200/4800 (46%)]	Loss: 10.182441
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 8.45h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 127500 Train Epoch: 26 [2700/4800 (56%)]	Loss: 9.810850
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.37h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 127500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 128000 Train Epoch: 26 [3200/4800 (67%)]	Loss: 10.518962
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.36h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 128500 Train Epoch: 26 [3700/4800 (77%)]	Loss: 10.059828
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.38h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 128500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 129000 Train Epoch: 26 [4200/4800 (88%)]	Loss: 10.865519
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.38h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129000 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 129500 Train Epoch: 26 [4700/4800 (98%)]	Loss: 10.539151
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.35h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129500 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep26.pth!
starting epoch  27
train 129600: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 129600 Train Epoch: 27 [0/4800 (0%)]	Loss: 10.356490
avg time for loading: 0.82s, logs: 0.26s, compute: 0.20s, total: 1.28s
ETA: 124.73h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129600 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129600 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129600 that is less than the current step 167058. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129600 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129600 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129600 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 129600 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 130000 Train Epoch: 27 [400/4800 (8%)]	Loss: 10.145308
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.24h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 130500 Train Epoch: 27 [900/4800 (19%)]	Loss: 10.444519
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.15h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 130500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 131000 Train Epoch: 27 [1400/4800 (29%)]	Loss: 9.820203
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 8.03h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 131500 Train Epoch: 27 [1900/4800 (40%)]	Loss: 10.632293
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.98h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 131500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 132000 Train Epoch: 27 [2400/4800 (50%)]	Loss: 10.145399
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.97h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 132500 Train Epoch: 27 [2900/4800 (60%)]	Loss: 10.437222
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.94h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 132500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 133000 Train Epoch: 27 [3400/4800 (71%)]	Loss: 10.511832
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.97h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 133500 Train Epoch: 27 [3900/4800 (81%)]	Loss: 10.278089
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.97h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 133500 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 134000 Train Epoch: 27 [4400/4800 (92%)]	Loss: 10.623250
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.99h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134000 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep27.pth!
starting epoch  28
train 134400: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 134400 Train Epoch: 28 [0/4800 (0%)]	Loss: 10.899792
avg time for loading: 0.98s, logs: 0.17s, compute: 0.16s, total: 1.31s
ETA: 126.01h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134400 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134400 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134400 that is less than the current step 167059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134400 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134400 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134400 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134400 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 134500 Train Epoch: 28 [100/4800 (2%)]	Loss: 10.268320
avg time for loading: 0.03s, logs: 0.00s, compute: 0.07s, total: 0.10s
ETA: 9.74h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 134500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 135000 Train Epoch: 28 [600/4800 (12%)]	Loss: 10.647950
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 8.23h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 135500 Train Epoch: 28 [1100/4800 (23%)]	Loss: 10.298689
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.91h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 135500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 136000 Train Epoch: 28 [1600/4800 (33%)]	Loss: 10.033976
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.87h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 136500 Train Epoch: 28 [2100/4800 (44%)]	Loss: 10.278715
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.97h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 136500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 137000 Train Epoch: 28 [2600/4800 (54%)]	Loss: 10.286400
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.90h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 137500 Train Epoch: 28 [3100/4800 (65%)]	Loss: 10.072987
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.87h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 137500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 138000 Train Epoch: 28 [3600/4800 (75%)]	Loss: 10.225154
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.90h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 138500 Train Epoch: 28 [4100/4800 (85%)]	Loss: 10.328211
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.90h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 138500 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 139000 Train Epoch: 28 [4600/4800 (96%)]	Loss: 10.128657
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.91h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139000 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep28.pth!
starting epoch  29
train 139200: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 139200 Train Epoch: 29 [0/4800 (0%)]	Loss: 9.959352
avg time for loading: 0.81s, logs: 0.19s, compute: 0.17s, total: 1.17s
ETA: 110.41h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139200 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139200 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139200 that is less than the current step 167060. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139200 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139200 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139200 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139200 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 139500 Train Epoch: 29 [300/4800 (6%)]	Loss: 10.456511
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 8.11h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 139500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 140000 Train Epoch: 29 [800/4800 (17%)]	Loss: 10.448461
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.74h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 140500 Train Epoch: 29 [1300/4800 (27%)]	Loss: 10.371306
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.76h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 140500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 141000 Train Epoch: 29 [1800/4800 (38%)]	Loss: 10.429830
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.74h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 141500 Train Epoch: 29 [2300/4800 (48%)]	Loss: 10.222841
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.71h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 141500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 142000 Train Epoch: 29 [2800/4800 (58%)]	Loss: 9.913013
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.67h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 142500 Train Epoch: 29 [3300/4800 (69%)]	Loss: 10.402102
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.74h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 142500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 143000 Train Epoch: 29 [3800/4800 (79%)]	Loss: 10.524398
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.76h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 143500 Train Epoch: 29 [4300/4800 (90%)]	Loss: 10.560664
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.74h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 143500 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep29.pth!
starting epoch  30
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144000 that is less than the current step 167061. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
train 144000: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 144000 Train Epoch: 30 [0/4800 (0%)]	Loss: 10.376993
avg time for loading: 0.90s, logs: 0.19s, compute: 0.18s, total: 1.26s
ETA: 117.83h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 144500 Train Epoch: 30 [500/4800 (10%)]	Loss: 10.118841
avg time for loading: 0.02s, logs: 0.00s, compute: 0.07s, total: 0.09s
ETA: 8.10h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 144500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 145000 Train Epoch: 30 [1000/4800 (21%)]	Loss: 10.829698
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.74h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 145500 Train Epoch: 30 [1500/4800 (31%)]	Loss: 10.546154
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.66h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 145500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 146000 Train Epoch: 30 [2000/4800 (42%)]	Loss: 10.504158
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.64h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 146500 Train Epoch: 30 [2500/4800 (52%)]	Loss: 10.180361
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.58h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 146500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 147000 Train Epoch: 30 [3000/4800 (62%)]	Loss: 10.501619
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.56h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 147500 Train Epoch: 30 [3500/4800 (73%)]	Loss: 10.598186
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.58h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 147500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 148000 Train Epoch: 30 [4000/4800 (83%)]	Loss: 10.573064
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.60h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148000 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 148500 Train Epoch: 30 [4500/4800 (94%)]	Loss: 10.475183
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.66h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148500 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep30.pth!
Running Testing
Eval time for batch:  2.845189094543457
mse: 0.010445030027767643
val 148800: logging videos

Test set: Average loss: 12.8930 in 3.90s

starting epoch  31
train 148800: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 148800 Train Epoch: 31 [0/4800 (0%)]	Loss: 10.063174
avg time for loading: 0.77s, logs: 0.19s, compute: 0.14s, total: 1.10s
ETA: 101.65h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167063. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167063. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167063. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167063. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167063. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 148800 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 149000 Train Epoch: 31 [200/4800 (4%)]	Loss: 10.510708
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 7.93h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 149500 Train Epoch: 31 [700/4800 (15%)]	Loss: 10.329730
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.62h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 149500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 150000 Train Epoch: 31 [1200/4800 (25%)]	Loss: 10.431773
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.58h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 150500 Train Epoch: 31 [1700/4800 (35%)]	Loss: 10.715038
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.53h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 150500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 151000 Train Epoch: 31 [2200/4800 (46%)]	Loss: 10.309515
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.46h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 151500 Train Epoch: 31 [2700/4800 (56%)]	Loss: 10.325560
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.48h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 151500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 152000 Train Epoch: 31 [3200/4800 (67%)]	Loss: 10.253325
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.48h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 152500 Train Epoch: 31 [3700/4800 (77%)]	Loss: 10.786859
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.47h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 152500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 153000 Train Epoch: 31 [4200/4800 (88%)]	Loss: 10.369949
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.51h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153000 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 153500 Train Epoch: 31 [4700/4800 (98%)]	Loss: 10.162948
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.52h
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep31.pth!
starting epoch  32
train 153600: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 153600 Train Epoch: 32 [0/4800 (0%)]	Loss: 10.762805
avg time for loading: 0.85s, logs: 0.22s, compute: 0.16s, total: 1.23s
ETA: 111.37h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153500 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153600 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153600 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153600 that is less than the current step 167064. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153600 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153600 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153600 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 153600 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 154000 Train Epoch: 32 [400/4800 (8%)]	Loss: 10.130471
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 8.00h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 154500 Train Epoch: 32 [900/4800 (19%)]	Loss: 10.919940
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.68h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 154500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 155000 Train Epoch: 32 [1400/4800 (29%)]	Loss: 10.338978
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.54h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 155500 Train Epoch: 32 [1900/4800 (40%)]	Loss: 10.500321
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.41h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 155500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 156000 Train Epoch: 32 [2400/4800 (50%)]	Loss: 10.235430
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.39h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 156500 Train Epoch: 32 [2900/4800 (60%)]	Loss: 10.827690
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.38h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 156500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 157000 Train Epoch: 32 [3400/4800 (71%)]	Loss: 10.214093
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.38h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 157500 Train Epoch: 32 [3900/4800 (81%)]	Loss: 10.763611
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.34h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 157500 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 158000 Train Epoch: 32 [4400/4800 (92%)]	Loss: 10.318715
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.37h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158000 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep32.pth!
starting epoch  33
train 158400: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 158400 Train Epoch: 33 [0/4800 (0%)]	Loss: 11.033232
avg time for loading: 0.93s, logs: 0.22s, compute: 0.16s, total: 1.31s
ETA: 117.24h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158400 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158400 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158400 that is less than the current step 167065. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158400 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158400 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158400 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158400 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 158500 Train Epoch: 33 [100/4800 (2%)]	Loss: 10.206796
avg time for loading: 0.03s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 8.48h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 158500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 159000 Train Epoch: 33 [600/4800 (12%)]	Loss: 10.163048
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 7.60h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 159500 Train Epoch: 33 [1100/4800 (23%)]	Loss: 10.553477
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.50h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 159500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 160000 Train Epoch: 33 [1600/4800 (33%)]	Loss: 10.469520
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.43h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 160500 Train Epoch: 33 [2100/4800 (44%)]	Loss: 10.593974
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.37h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 160500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 161000 Train Epoch: 33 [2600/4800 (54%)]	Loss: 10.669638
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.35h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 161500 Train Epoch: 33 [3100/4800 (65%)]	Loss: 10.177667
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.34h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 161500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 162000 Train Epoch: 33 [3600/4800 (75%)]	Loss: 10.638183
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.33h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 162500 Train Epoch: 33 [4100/4800 (85%)]	Loss: 10.513365
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.37h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 162500 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 163000 Train Epoch: 33 [4600/4800 (96%)]	Loss: 10.743686
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.38h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163000 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep33.pth!
starting epoch  34
train 163200: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 163200 Train Epoch: 34 [0/4800 (0%)]	Loss: 10.925777
avg time for loading: 0.89s, logs: 0.26s, compute: 0.18s, total: 1.32s
ETA: 116.44h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163200 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163200 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163200 that is less than the current step 167066. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163200 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163200 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163200 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163200 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 163500 Train Epoch: 34 [300/4800 (6%)]	Loss: 11.337735
avg time for loading: 0.02s, logs: 0.00s, compute: 0.07s, total: 0.09s
ETA: 7.67h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 163500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 164000 Train Epoch: 34 [800/4800 (17%)]	Loss: 10.426600
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.46h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 164500 Train Epoch: 34 [1300/4800 (27%)]	Loss: 10.525038
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.34h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 164500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 165000 Train Epoch: 34 [1800/4800 (38%)]	Loss: 10.294441
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.31h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 165500 Train Epoch: 34 [2300/4800 (48%)]	Loss: 10.668913
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.22h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 165500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 166000 Train Epoch: 34 [2800/4800 (58%)]	Loss: 10.483221
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.21h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 166500 Train Epoch: 34 [3300/4800 (69%)]	Loss: 10.631426
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.23h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 166500 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 167000 Train Epoch: 34 [3800/4800 (79%)]	Loss: 10.748164
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.20h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 167000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 167000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 167000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 167000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 167000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 167000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 167000 that is less than the current step 167067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 167500 Train Epoch: 34 [4300/4800 (90%)]	Loss: 10.745860
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.25h
Saved checkpoint to ./experiments/skill_prior_learning/kitchen/hierarchical_cl/weights/weights_ep34.pth!
starting epoch  35
train 168000: logging videos
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 168000 Train Epoch: 35 [0/4800 (0%)]	Loss: 10.381096
avg time for loading: 0.72s, logs: 0.23s, compute: 0.17s, total: 1.12s
ETA: 97.16h
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 168000 that is less than the current step 168001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 168000 that is less than the current step 168001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 168000 that is less than the current step 168001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 168000 that is less than the current step 168001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 168500 Train Epoch: 35 [500/4800 (10%)]	Loss: 10.495108
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.09s
ETA: 7.69h
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 169000 Train Epoch: 35 [1000/4800 (21%)]	Loss: 9.919483
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.24h
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 169500 Train Epoch: 35 [1500/4800 (31%)]	Loss: 10.945005
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.30h
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 170000 Train Epoch: 35 [2000/4800 (42%)]	Loss: 10.519966
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.29h
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 170500 Train Epoch: 35 [2500/4800 (52%)]	Loss: 9.910717
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.24h
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 171000 Train Epoch: 35 [3000/4800 (62%)]	Loss: 10.622040
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.20h
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 171500 Train Epoch: 35 [3500/4800 (73%)]	Loss: 10.421329
avg time for loading: 0.02s, logs: 0.00s, compute: 0.06s, total: 0.08s
ETA: 7.21h
GPU none: ./experiments/skill_prior_learning/kitchen/hierarchical_cl
itr: 172000 Train Epoch: 35 [4000/4800 (83%)]	Loss: 10.586963
avg time for loading: 0.02s, logs: 0.00s, compute: 0.26s, total: 0.28s
ETA: 24.58h
